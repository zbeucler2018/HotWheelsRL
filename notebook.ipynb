{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V4N_h3NAz6ud",
    "outputId": "5ed67161-e19a-40b0-f111-bd431f32f665"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.16\n",
      "pip 22.0.4 from /usr/local/lib/python3.8/site-packages/pip (python 3.8)\n"
     ]
    }
   ],
   "source": [
    "!python --version\n",
    "!pip --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created symlink: /usr/local/lib/python3.8/site-packages/retro/data/stable/HotWheelsStuntTrackChallenge-gba -> /home/rom\n",
      "Importing HotWheelsStuntTrackChallenge-gba\n",
      "Importing HotWheelsStuntTrackChallenge-gba\n",
      "Imported 2 games\n"
     ]
    }
   ],
   "source": [
    "!bash import_rom_into_retro.bash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1IBpq2YJJwHQ"
   },
   "source": [
    "# Utils\n",
    "\n",
    "\n",
    "    imshow(frame)\n",
    "    create_video(frames, filename, fps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "OUkNHNa9Jvpf"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "#import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "\n",
    "def imshow(obs):\n",
    "  \"\"\"\n",
    "  displays a 3d numpy array\n",
    "  \"\"\"\n",
    "  plt.imshow(obs, interpolation='nearest')\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def create_video(frames, filename, fps=30):\n",
    "  \"\"\"\n",
    "  converts frames into a mp4. create_video(frames, 'video.mp4')\n",
    "  \"\"\"\n",
    "  height, width, _ = frames[0].shape\n",
    "  fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "  video_writer = cv2.VideoWriter(filename, fourcc, fps, (width, height))\n",
    "  for frame in frames:\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    video_writer.write(frame)\n",
    "    video_writer.release()\n",
    "  print(f\"Video saved as {os.getcwd()}/{filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8k4nKwSn2zOX"
   },
   "source": [
    "# Env utils\n",
    "\n",
    "\n",
    "- [ ] speed fix wrapper\n",
    "- [ ] score reward wrapper\n",
    "- [ ] Timestep penality wrapper\n",
    "- [ ] button restriction wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VQv8nKht1R5w"
   },
   "outputs": [],
   "source": [
    "import retro\n",
    "from stable_baselines3.common.atari_wrappers import WarpFrame, ClipRewardEnv\n",
    "from gymnasium.wrappers import GrayScaleObservation, TimeLimit\n",
    "from stable_baselines3.common.vec_env import VecFrameStack\n",
    "from gymnasium.spaces import MultiBinary\n",
    "from enum import Enum\n",
    "\n",
    "\n",
    "\n",
    "def make_hot_wheels_env():\n",
    "  env = retro.make(\"HotWheelsStuntTrackChallenge-gba\", render_mode=\"rgb_array\")\n",
    "  env = GrayScaleObservation(env, keep_dim=True)\n",
    "  env = VecFrameStack(env, n_stack=4)\n",
    "  env = TimeLimit(env, max_episode_steps=15_000)\n",
    "  return env\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class HotWheelsButtons(Enum):\n",
    "  ALL = ['B', None, 'SELECT', 'START', 'UP', 'DOWN', 'LEFT', 'RIGHT', 'A', None, 'L', 'R'],\n",
    "  FILTERED = ['B', 'UP', 'DOWN', 'LEFT', 'RIGHT', 'A', 'L', 'R']\n",
    "\n",
    "\n",
    "\n",
    "class HotWheelsEnv(retro.RetroEnv):\n",
    "    def __init__(self, game, state=None, scenario=None):\n",
    "        super().__init__(game, state=state, scenario=scenario)\n",
    "\n",
    "    def step(self, action):\n",
    "        # fix speed \n",
    "        info['speed'] = info['speed'] * 0.702\n",
    "        return observation, reward, terminated, truncated, info\n",
    "\n",
    "\n",
    "class TimePenaltyWrapper(gymnasium.Wrapper):\n",
    "    def __init__(self, env, time_penalty=0.1):\n",
    "        super().__init__(env)\n",
    "        self.time_penalty = time_penalty\n",
    "\n",
    "    def step(self, action):\n",
    "        observation, reward, terminated, truncated, info = self.env.step(action)\n",
    "        # add a penalty for each time step that the agent takes\n",
    "        reward -= self.time_penalty\n",
    "        if terminated or truncated:\n",
    "            # add a bonus reward for reaching the goal in the fewest number of time steps\n",
    "            reward += (self.env.unwrapped.time * 10)\n",
    "        return observation, reward, terminated, truncated, info\n",
    "\n",
    "\n",
    "import gymnasium as gym\n",
    "\n",
    "class FixSpeedWrapper(gym.Wrapper):\n",
    "  \"\"\"\n",
    "  Fixes env bug so the speed is accurate\n",
    "  \"\"\"\n",
    "  def __init__(self, env):\n",
    "    super().__init__(env)\n",
    "\n",
    "  def step(self, action):\n",
    "    observation, reward, terminated, truncated, info = self.env.step(action)\n",
    "    info['speed'] *= 0.702\n",
    "    return observation, reward, terminated, truncated, info\n",
    "\n",
    "\n",
    "\n",
    "class FixSpeedWrapper(gym.Wrapper):\n",
    "  \"\"\"\n",
    "  Fixes env bug so the speed is accurate\n",
    "  \"\"\"\n",
    "  def __init__(self, env):\n",
    "    super().__init__(env)\n",
    "\n",
    "  def step(self, action):\n",
    "    observation, reward, terminated, truncated, info = self.env.step(action)\n",
    "    info['speed'] *= 0.702\n",
    "    return observation, reward, terminated, truncated, info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VoOvv7md8_R5"
   },
   "source": [
    "# load tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KFtdqtdsaGZJ"
   },
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q4XU0EFREvc_"
   },
   "source": [
    "## Train PPO sb3 model\n",
    "\n",
    "\n",
    "[Tensorboard PPO article](https://medium.com/aureliantactics/understanding-ppo-plots-in-tensorboard-cbc3199b9ba2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RJnLIxUj191W"
   },
   "outputs": [],
   "source": [
    "import retro\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3 import PPO\n",
    "\n",
    "\n",
    "# make env\n",
    "env = retro.make(\"HotWheelsStuntTrackChallenge-gba\", render_mode=\"rgb_array\")\n",
    "observation, info = env.reset(seed=42)\n",
    "\n",
    "\n",
    "# check if valid env\n",
    "try:\n",
    "  check_env(env)\n",
    "except Exception as err:\n",
    "  env.close()\n",
    "  print(err)\n",
    "  raise\n",
    "\n",
    "\n",
    "# train model\n",
    "try:\n",
    "  model = PPO('CnnPolicy', env, verbose=1, tensorboard_log='/content/HotWheelsRL/logs', learning_rate=0.000001)\n",
    "  model.learn(total_timesteps=10_000)\n",
    "except Exception as err:\n",
    "  env.close()\n",
    "  print(err)\n",
    "  raise\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4WS9hi69pui3"
   },
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G-ORG6fL3tKx"
   },
   "source": [
    "# PPO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v5oU_yWhAJxh"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9NfnwyrQJuPN"
   },
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO\n",
    "\n",
    "model = PPO('CnnPolicy', env, verbose=1, tensorboard_log=\"/content/HotWheelsRL/logs\")\n",
    "model.learn(25_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MraSRDV-AZ4D"
   },
   "source": [
    "## Save/load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i5jVz-p4Ae_1"
   },
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO\n",
    "\n",
    "\n",
    "filename = \"ppo_25k_cnn\"\n",
    "filepath = f\"/content/gdrive/MyDrive/theLab_/HotWheelsRL/{filename}\"\n",
    "\n",
    "#model.save(filepath)\n",
    "#del model\n",
    "model = PPO.load(filepath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IhDo9kub_wX2"
   },
   "source": [
    "## Run agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xSPzdNyOZoYf"
   },
   "outputs": [],
   "source": [
    "env = retro.make(\"HotWheelsStuntTrackChallenge-gba\", render_mode=\"rgb_array\")\n",
    "obs, info = env.reset(seed=42)\n",
    "\n",
    "\n",
    "total_reward = 0\n",
    "\n",
    "\n",
    "while True:\n",
    "\n",
    "    action, _states = model.predict(obs, deterministic=True)\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "    env.render()\n",
    "    total_reward += reward\n",
    "\n",
    "    print(info['progress'], reward, total_reward, env.get_action_meaning(action))\n",
    "\n",
    "    if terminated or truncated:\n",
    "      imshow(obs)\n",
    "      break\n",
    "\n",
    "env.close()\n",
    "\n",
    "print(total_reward, terminated, truncated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aDIXY34XK6K9"
   },
   "source": [
    "# Train A2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EwvIKj8HK-C4"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "from stable_baselines3 import A2C\n",
    "\n",
    "# import the rom into retro\n",
    "import_rom()\n",
    "\n",
    "env = retro.make(\"HotWheelsStuntTrackChallenge-gba\", render_mode=\"rgb_array\")\n",
    "obs, info = env.reset(seed=42)\n",
    "\n",
    "\n",
    "model = A2C('CnnPolicy', env, verbose=1, tensorboard_log=\"/content/HotWheelsRL/logs\")\n",
    "model.learn(25_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ypXIo2iuP9L3"
   },
   "source": [
    "## save A2C model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CX1YyB4sOuDc"
   },
   "outputs": [],
   "source": [
    "from stable_baselines3 import A2C\n",
    "\n",
    "\n",
    "filename = \"a2c_25k_cnn\"\n",
    "filepath = f\"/content/gdrive/MyDrive/theLab_/HotWheelsRL/{filename}\"\n",
    "\n",
    "#model.save(filepath)\n",
    "#del model\n",
    "model = A2C.load(filepath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ybw6VWnaQBI9"
   },
   "source": [
    "## Run A2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ArWBMBegQHo4"
   },
   "outputs": [],
   "source": [
    "#env = retro.make(\"HotWheelsStuntTrackChallenge-gba\", render_mode=\"rgb_array\")\n",
    "observation, info = env.reset()\n",
    "\n",
    "totalFrames = 0\n",
    "totalReward = 0\n",
    "frames = []\n",
    "while True:\n",
    "  action, _state = model.predict(observation, deterministic=True)\n",
    "  observation, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "  totalFrames += 1\n",
    "  totalReward += reward\n",
    "  frames.append(observation)\n",
    "\n",
    "\n",
    "  if totalFrames % 50 == 0:\n",
    "    print(info, totalFrames, env.get_action_meaning(action))\n",
    "\n",
    "\n",
    "  if terminated or truncated:\n",
    "    imshow(observation)\n",
    "    break\n",
    "\n",
    "env.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fer1lu5x78fX"
   },
   "source": [
    "## Save agent trial to mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SC_2aDoq8A5v"
   },
   "outputs": [],
   "source": [
    "gif_name = \"a2c_25k_cnn\"\n",
    "gif_path = f\"/content/gdrive/MyDrive/theLab_/HotWheelsRL/{gif_name}\"\n",
    "create_video(frames, gif_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vIqaMU6l8M46"
   },
   "source": [
    "# Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YhSkIIzj3YSD"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "q4XU0EFREvc_",
    "G-ORG6fL3tKx"
   ],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
