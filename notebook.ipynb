{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4N_h3NAz6ud",
        "outputId": "5ed67161-e19a-40b0-f111-bd431f32f665"
      },
      "outputs": [],
      "source": [
        "!python --version\n",
        "!pip --version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IBpq2YJJwHQ"
      },
      "source": [
        "# Utils\n",
        "\n",
        "    import_rom(local=False)\n",
        "    load_model_from_gdrive(model_path)\n",
        "    save_model_in_gdrive(model_path)\n",
        "    load_model_from_local_drive()\n",
        "    download_colab_file_to_local_drive(filename)\n",
        "    imshow(frame)\n",
        "    create_video(frames, filename, fps=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OUkNHNa9Jvpf"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "import os\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import cv2\n",
        "from google.colab import files, drive\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def uploadFromLocalDrive():\n",
        "  uploaded = files.upload()\n",
        "  destination_path = \"/content/HotWheelsRL/rom\"\n",
        "  filename = list(uploaded.keys())[0]\n",
        "  try:\n",
        "      shutil.move(filename, os.path.join(destination_path, filename))\n",
        "  except Exception as err:\n",
        "    raise Exception(err)\n",
        "\n",
        "\n",
        "\n",
        "def uploadFromGoogleDrive():\n",
        "  drive.mount('/content/gdrive')\n",
        "  source = \"/content/gdrive/MyDrive/theLab_/HotWheelsRL/rom.gba\"\n",
        "  dest = \"/content/HotWheelsRL/rom/rom.gba\"\n",
        "  try:\n",
        "    shutil.copy(source, dest)\n",
        "  except Exception as err:\n",
        "    raise Exception(err)\n",
        "\n",
        "\n",
        "\n",
        "def import_rom(local=False):\n",
        "  \"\"\"\n",
        "  Downloads the ROM from gdrive or local drive, creates a symlink to the HotWheelsRL/rom folder\n",
        "  to allow for importing the rom into stable-retro\n",
        "  \"\"\"\n",
        "  if local:\n",
        "    uploadFromLocalDrive()\n",
        "  else:\n",
        "    uploadFromGoogleDrive()\n",
        "  folder_name=\"/content/HotWheelsRL/rom\"\n",
        "  link_name=\"HotWheelsStuntTrackChallenge-gba\"\n",
        "  lib_path=\"/usr/local/lib/python3.8/dist-packages/retro/data/stable\"\n",
        "  # Validate input and handle errors\n",
        "  if not Path(folder_name).is_dir():\n",
        "      raise ValueError(f\"{folder_name} is not a valid directory.\")\n",
        "  if not Path(lib_path).is_dir():\n",
        "      raise ValueError(f\"{lib_path} is not a valid directory.\")\n",
        "  # Define paths as Path objects\n",
        "  source_path = Path.cwd() / folder_name\n",
        "  dest_path = Path(lib_path) / link_name\n",
        "  # Use Path.symlink_to() to create the symbolic link\n",
        "  try:\n",
        "      dest_path.symlink_to(source_path)\n",
        "      print(f\"Created symlink: {dest_path} -> {source_path}\")\n",
        "  except OSError as e:\n",
        "      print(f\"Error creating symlink: {e}\")\n",
        "\n",
        "      \n",
        "  os.system('python -m retro.import /content/HotWheelsRL/rom/')\n",
        "  return\n",
        "\n",
        "\n",
        "\n",
        "def download_colab_file_to_local_drive(filename):\n",
        "  \"\"\"\n",
        "  Downloads a file from the cloud instance to the local computer\n",
        "  \"\"\"\n",
        "  try:\n",
        "    files.download(filename)\n",
        "  except Exception as err:\n",
        "    print('Could not save file, is the path correct?')\n",
        "    print(err)\n",
        "    raise\n",
        "\n",
        "\n",
        "\n",
        "def imshow(obs):\n",
        "  \"\"\"\n",
        "  displays a 3d numpy array\n",
        "  \"\"\"\n",
        "  plt.imshow(obs, interpolation='nearest')\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "\n",
        "def create_video(frames, filename, fps=30):\n",
        "  \"\"\"\n",
        "  converts frames into a mp4. create_video(frames, 'video.mp4')\n",
        "  \"\"\"\n",
        "  height, width, _ = frames[0].shape\n",
        "  fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
        "  video_writer = cv2.VideoWriter(filename, fourcc, fps, (width, height))\n",
        "  for frame in frames:\n",
        "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    video_writer.write(frame)\n",
        "    video_writer.release()\n",
        "  print(f\"Video saved as {os.getcwd()}/{filename}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8k4nKwSn2zOX"
      },
      "source": [
        "# Env utils\n",
        "\n",
        "\n",
        "- [ ] speed fix wrapper\n",
        "- [ ] score reward wrapper\n",
        "- [ ] Timestep penality wrapper\n",
        "- [ ] button restriction wrapper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQv8nKht1R5w"
      },
      "outputs": [],
      "source": [
        "import retro\n",
        "from stable_baselines3.common.atari_wrappers import WarpFrame, ClipRewardEnv\n",
        "from gymnasium.wrappers import GrayScaleObservation, TimeLimit\n",
        "from stable_baselines3.common.vec_env import VecFrameStack\n",
        "from gymnasium.spaces import MultiBinary\n",
        "from enum import Enum\n",
        "\n",
        "\n",
        "\n",
        "def make_hot_wheels_env():\n",
        "  env = retro.make(\"HotWheelsStuntTrackChallenge-gba\", render_mode=\"rgb_array\")\n",
        "  env = GrayScaleObservation(env, keep_dim=True)\n",
        "  env = VecFrameStack(env, n_stack=4)\n",
        "  env = TimeLimit(env, max_episode_steps=15_000)\n",
        "  return env\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class HotWheelsButtons(Enum):\n",
        "  ALL = ['B', None, 'SELECT', 'START', 'UP', 'DOWN', 'LEFT', 'RIGHT', 'A', None, 'L', 'R'],\n",
        "  FILTERED = ['B', 'UP', 'DOWN', 'LEFT', 'RIGHT', 'A', 'L', 'R']\n",
        "\n",
        "\n",
        "\n",
        "class HotWheelsEnv(retro.RetroEnv):\n",
        "    def __init__(self, game, state=None, scenario=None):\n",
        "        super().__init__(game, state=state, scenario=scenario)\n",
        "\n",
        "    def step(self, action):\n",
        "        # fix speed \n",
        "        info['speed0'] = info['speed0'] * 0.702\n",
        "        return observation, reward, terminated, truncated, info\n",
        "\n",
        "\n",
        "class TimePenaltyWrapper(gymnasium.Wrapper):\n",
        "    def __init__(self, env, time_penalty=0.1):\n",
        "        super().__init__(env)\n",
        "        self.time_penalty = time_penalty\n",
        "\n",
        "    def step(self, action):\n",
        "        observation, reward, terminated, truncated, info = self.env.step(action)\n",
        "        # add a penalty for each time step that the agent takes\n",
        "        reward -= self.time_penalty\n",
        "        if terminated or truncated:\n",
        "            # add a bonus reward for reaching the goal in the fewest number of time steps\n",
        "            reward += (self.env.unwrapped.time * 10)\n",
        "        return observation, reward, terminated, truncated, info\n",
        "\n",
        "\n",
        "import gymnasium as gym\n",
        "\n",
        "class FixSpeedWrapper(gym.Wrapper):\n",
        "  \"\"\"\n",
        "  Fixes env bug so the speed is accurate\n",
        "  \"\"\"\n",
        "  def __init__(self, env):\n",
        "    super().__init__(env)\n",
        "\n",
        "  def step(self, action):\n",
        "    observation, reward, terminated, truncated, info = self.env.step(action)\n",
        "    info['speed'] *= 0.702\n",
        "    return observation, reward, terminated, truncated, info\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fT6WKsr9E00"
      },
      "source": [
        "# load rom into gym-retro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8iwz2uf0k8ab"
      },
      "outputs": [],
      "source": [
        "!ls -lA /usr/local/lib/python3.8/dist-packages/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uA6iHK9k9IiL"
      },
      "outputs": [],
      "source": [
        "import_rom()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VoOvv7md8_R5"
      },
      "source": [
        "# load tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KFtdqtdsaGZJ"
      },
      "outputs": [],
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4XU0EFREvc_"
      },
      "source": [
        "## Train PPO sb3 model\n",
        "\n",
        "\n",
        "[Tensorboard PPO article](https://medium.com/aureliantactics/understanding-ppo-plots-in-tensorboard-cbc3199b9ba2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJnLIxUj191W"
      },
      "outputs": [],
      "source": [
        "import retro\n",
        "from stable_baselines3.common.env_checker import check_env\n",
        "from stable_baselines3 import PPO\n",
        "\n",
        "\n",
        "# import the rom into retro\n",
        "import_rom()\n",
        "\n",
        "\n",
        "# make env\n",
        "env = retro.make(\"HotWheelsStuntTrackChallenge-gba\", render_mode=\"rgb_array\")\n",
        "observation, info = env.reset(seed=42)\n",
        "\n",
        "\n",
        "# check if valid env\n",
        "try:\n",
        "  check_env(env)\n",
        "except Exception as err:\n",
        "  env.close()\n",
        "  print(err)\n",
        "  raise\n",
        "\n",
        "\n",
        "# train model\n",
        "try:\n",
        "  model = PPO('CnnPolicy', env, verbose=1, tensorboard_log='/content/HotWheelsRL/logs', learning_rate=0.000001)\n",
        "  model.learn(total_timesteps=10_000)\n",
        "except Exception as err:\n",
        "  env.close()\n",
        "  print(err)\n",
        "  raise\n",
        "\n",
        "env.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4WS9hi69pui3"
      },
      "outputs": [],
      "source": [
        "env.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-ORG6fL3tKx"
      },
      "source": [
        "# PPO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5oU_yWhAJxh"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9NfnwyrQJuPN"
      },
      "outputs": [],
      "source": [
        "from stable_baselines3 import PPO\n",
        "\n",
        "model = PPO('CnnPolicy', env, verbose=1, tensorboard_log=\"/content/HotWheelsRL/logs\")\n",
        "model.learn(25_000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MraSRDV-AZ4D"
      },
      "source": [
        "## Save/load model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5jVz-p4Ae_1"
      },
      "outputs": [],
      "source": [
        "from stable_baselines3 import PPO\n",
        "\n",
        "\n",
        "filename = \"ppo_25k_cnn\"\n",
        "filepath = f\"/content/gdrive/MyDrive/theLab_/HotWheelsRL/{filename}\"\n",
        "\n",
        "#model.save(filepath)\n",
        "#del model\n",
        "model = PPO.load(filepath)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhDo9kub_wX2"
      },
      "source": [
        "## Run agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xSPzdNyOZoYf"
      },
      "outputs": [],
      "source": [
        "env = retro.make(\"HotWheelsStuntTrackChallenge-gba\", render_mode=\"rgb_array\")\n",
        "obs, info = env.reset(seed=42)\n",
        "\n",
        "\n",
        "total_reward = 0\n",
        "\n",
        "\n",
        "while True:\n",
        "\n",
        "    action, _states = model.predict(obs, deterministic=True)\n",
        "    obs, reward, terminated, truncated, info = env.step(action)\n",
        "    env.render()\n",
        "    total_reward += reward\n",
        "\n",
        "    print(info['progress'], reward, total_reward, env.get_action_meaning(action))\n",
        "\n",
        "    if terminated or truncated:\n",
        "      imshow(obs)\n",
        "      break\n",
        "\n",
        "env.close()\n",
        "\n",
        "print(total_reward, terminated, truncated)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDIXY34XK6K9"
      },
      "source": [
        "# Train A2C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EwvIKj8HK-C4"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "\n",
        "from stable_baselines3 import A2C\n",
        "\n",
        "# import the rom into retro\n",
        "import_rom()\n",
        "\n",
        "env = retro.make(\"HotWheelsStuntTrackChallenge-gba\", render_mode=\"rgb_array\")\n",
        "obs, info = env.reset(seed=42)\n",
        "\n",
        "\n",
        "model = A2C('CnnPolicy', env, verbose=1, tensorboard_log=\"/content/HotWheelsRL/logs\")\n",
        "model.learn(25_000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypXIo2iuP9L3"
      },
      "source": [
        "## save A2C model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CX1YyB4sOuDc"
      },
      "outputs": [],
      "source": [
        "from stable_baselines3 import A2C\n",
        "\n",
        "\n",
        "filename = \"a2c_25k_cnn\"\n",
        "filepath = f\"/content/gdrive/MyDrive/theLab_/HotWheelsRL/{filename}\"\n",
        "\n",
        "#model.save(filepath)\n",
        "#del model\n",
        "model = A2C.load(filepath)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybw6VWnaQBI9"
      },
      "source": [
        "## Run A2C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ArWBMBegQHo4"
      },
      "outputs": [],
      "source": [
        "#env = retro.make(\"HotWheelsStuntTrackChallenge-gba\", render_mode=\"rgb_array\")\n",
        "observation, info = env.reset()\n",
        "\n",
        "totalFrames = 0\n",
        "totalReward = 0\n",
        "frames = []\n",
        "while True:\n",
        "  action, _state = model.predict(observation, deterministic=True)\n",
        "  observation, reward, terminated, truncated, info = env.step(action)\n",
        "\n",
        "  totalFrames += 1\n",
        "  totalReward += reward\n",
        "  frames.append(observation)\n",
        "\n",
        "\n",
        "  if totalFrames % 50 == 0:\n",
        "    print(info, totalFrames, env.get_action_meaning(action))\n",
        "\n",
        "\n",
        "  if terminated or truncated:\n",
        "    imshow(observation)\n",
        "    break\n",
        "\n",
        "env.close()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fer1lu5x78fX"
      },
      "source": [
        "## Save agent trial to mp4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SC_2aDoq8A5v"
      },
      "outputs": [],
      "source": [
        "gif_name = \"a2c_25k_cnn\"\n",
        "gif_path = f\"/content/gdrive/MyDrive/theLab_/HotWheelsRL/{gif_name}\"\n",
        "create_video(frames, gif_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIqaMU6l8M46"
      },
      "source": [
        "# Misc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YhSkIIzj3YSD"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "q4XU0EFREvc_",
        "G-ORG6fL3tKx"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
